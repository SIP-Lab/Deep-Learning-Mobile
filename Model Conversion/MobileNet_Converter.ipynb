{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the Python Libraries Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:TensorFlow version 1.12.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import keras.backend as K\n",
    "from tensorflow.python.framework import graph_util, graph_io\n",
    "import coremltools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the learning phase using the backend as False and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(False)\n",
    "\n",
    "# Load the model with the weights trained on Imagenet \n",
    "model = MobileNet(weights='imagenet',include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model into a coreml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output name length mismatch\n",
      "0 : input_1, <keras.engine.topology.InputLayer object at 0x10d8a3208>\n",
      "1 : conv1_pad, <keras.layers.convolutional.ZeroPadding2D object at 0xd2b320cc0>\n",
      "2 : conv1, <keras.layers.convolutional.Conv2D object at 0xd2b320a90>\n",
      "3 : conv1_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b320c50>\n",
      "4 : conv1_relu, <keras.layers.core.Activation object at 0xd2b320eb8>\n",
      "5 : conv_pad_1, <keras.layers.convolutional.ZeroPadding2D object at 0xd2b348208>\n",
      "6 : conv_dw_1, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2b348e48>\n",
      "7 : conv_dw_1_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b36acf8>\n",
      "8 : conv_dw_1_relu, <keras.layers.core.Activation object at 0xd2b449e48>\n",
      "9 : conv_pw_1, <keras.layers.convolutional.Conv2D object at 0xd2b4887f0>\n",
      "10 : conv_pw_1_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b488128>\n",
      "11 : conv_pw_1_relu, <keras.layers.core.Activation object at 0xd2b4f1048>\n",
      "12 : conv_pad_2, <keras.layers.convolutional.ZeroPadding2D object at 0xd2b593278>\n",
      "13 : conv_dw_2, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2b624f28>\n",
      "14 : conv_dw_2_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b5936a0>\n",
      "15 : conv_dw_2_relu, <keras.layers.core.Activation object at 0xd2b603048>\n",
      "16 : conv_pw_2, <keras.layers.convolutional.Conv2D object at 0xd2b6a5ba8>\n",
      "17 : conv_pw_2_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b6a54e0>\n",
      "18 : conv_pw_2_relu, <keras.layers.core.Activation object at 0xd2b713860>\n",
      "19 : conv_pad_3, <keras.layers.convolutional.ZeroPadding2D object at 0xd2b7a15f8>\n",
      "20 : conv_dw_3, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2b7a1fd0>\n",
      "21 : conv_dw_3_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b7d6940>\n",
      "22 : conv_dw_3_relu, <keras.layers.core.Activation object at 0xd2b81f860>\n",
      "23 : conv_pw_3, <keras.layers.convolutional.Conv2D object at 0xd2b8b5f28>\n",
      "24 : conv_pw_3_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b8b5860>\n",
      "25 : conv_pw_3_relu, <keras.layers.core.Activation object at 0xd2b931b38>\n",
      "26 : conv_pad_4, <keras.layers.convolutional.ZeroPadding2D object at 0xd2ba15d68>\n",
      "27 : conv_dw_4, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2b9c5e10>\n",
      "28 : conv_dw_4_bn, <keras.layers.normalization.BatchNormalization object at 0xd2b9c5da0>\n",
      "29 : conv_dw_4_relu, <keras.layers.core.Activation object at 0xd2ba42b38>\n",
      "30 : conv_pw_4, <keras.layers.convolutional.Conv2D object at 0xd2bad5d68>\n",
      "31 : conv_pw_4_bn, <keras.layers.normalization.BatchNormalization object at 0xd2bad5be0>\n",
      "32 : conv_pw_4_relu, <keras.layers.core.Activation object at 0xd2bb46e80>\n",
      "33 : conv_pad_5, <keras.layers.convolutional.ZeroPadding2D object at 0xd2bbdccc0>\n",
      "34 : conv_dw_5, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2bbdccf8>\n",
      "35 : conv_dw_5_bn, <keras.layers.normalization.BatchNormalization object at 0xd2bc36208>\n",
      "36 : conv_dw_5_relu, <keras.layers.core.Activation object at 0xd2bcebf60>\n",
      "37 : conv_pw_5, <keras.layers.convolutional.Conv2D object at 0xd2bd2b668>\n",
      "38 : conv_pw_5_bn, <keras.layers.normalization.BatchNormalization object at 0xd2bd2b0f0>\n",
      "39 : conv_pw_5_relu, <keras.layers.core.Activation object at 0xd2bdfae48>\n",
      "40 : conv_pad_6, <keras.layers.convolutional.ZeroPadding2D object at 0xd2be3c4e0>\n",
      "41 : conv_dw_6, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2be7ae48>\n",
      "42 : conv_dw_6_bn, <keras.layers.normalization.BatchNormalization object at 0xd2be3c9e8>\n",
      "43 : conv_dw_6_relu, <keras.layers.core.Activation object at 0xd2bf09f60>\n",
      "44 : conv_pw_6, <keras.layers.convolutional.Conv2D object at 0xd2bf4d908>\n",
      "45 : conv_pw_6_bn, <keras.layers.normalization.BatchNormalization object at 0xd2bf4d240>\n",
      "46 : conv_pw_6_relu, <keras.layers.core.Activation object at 0xd2bfb4080>\n",
      "47 : conv_pad_7, <keras.layers.convolutional.ZeroPadding2D object at 0xd2c045438>\n",
      "48 : conv_dw_7, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2c045d30>\n",
      "49 : conv_dw_7_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c079630>\n",
      "50 : conv_dw_7_relu, <keras.layers.core.Activation object at 0xd2c0c4080>\n",
      "51 : conv_pw_7, <keras.layers.convolutional.Conv2D object at 0xd2c157d68>\n",
      "52 : conv_pw_7_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c1576a0>\n",
      "53 : conv_pw_7_relu, <keras.layers.core.Activation object at 0xd2c1d04a8>\n",
      "54 : conv_pad_8, <keras.layers.convolutional.ZeroPadding2D object at 0xd2c2b9e10>\n",
      "55 : conv_dw_8, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2c269ac8>\n",
      "56 : conv_dw_8_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c269be0>\n",
      "57 : conv_dw_8_relu, <keras.layers.core.Activation object at 0xd2c2e44a8>\n",
      "58 : conv_pw_8, <keras.layers.convolutional.Conv2D object at 0xd2c3a9e10>\n",
      "59 : conv_pw_8_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c352978>\n",
      "60 : conv_pw_8_relu, <keras.layers.core.Activation object at 0xd2c3f1cf8>\n",
      "61 : conv_pad_9, <keras.layers.convolutional.ZeroPadding2D object at 0xd2c4bcd30>\n",
      "62 : conv_dw_9, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2c480e48>\n",
      "63 : conv_dw_9_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c480da0>\n",
      "64 : conv_dw_9_relu, <keras.layers.core.Activation object at 0xd2c500cf8>\n",
      "65 : conv_pw_9, <keras.layers.convolutional.Conv2D object at 0xd2c58ff28>\n",
      "66 : conv_pw_9_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c58fda0>\n",
      "67 : conv_pw_9_relu, <keras.layers.core.Activation object at 0xd2c60db00>\n",
      "68 : conv_pad_10, <keras.layers.convolutional.ZeroPadding2D object at 0xd2c6e1470>\n",
      "69 : conv_dw_10, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2c69ec88>\n",
      "70 : conv_dw_10_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c6fe3c8>\n",
      "71 : conv_dw_10_relu, <keras.layers.core.Activation object at 0xd2c7c2e80>\n",
      "72 : conv_pw_10, <keras.layers.convolutional.Conv2D object at 0xd2c802828>\n",
      "73 : conv_pw_10_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c802160>\n",
      "74 : conv_pw_10_relu, <keras.layers.core.Activation object at 0xd2c86d048>\n",
      "75 : conv_pad_11, <keras.layers.convolutional.ZeroPadding2D object at 0xd2c90e278>\n",
      "76 : conv_dw_11, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2c9a0f28>\n",
      "77 : conv_dw_11_bn, <keras.layers.normalization.BatchNormalization object at 0xd2c90e6a0>\n",
      "78 : conv_dw_11_relu, <keras.layers.core.Activation object at 0xd2c97e048>\n",
      "79 : conv_pw_11, <keras.layers.convolutional.Conv2D object at 0xd2ca1fba8>\n",
      "80 : conv_pw_11_bn, <keras.layers.normalization.BatchNormalization object at 0xd2ca1f4e0>\n",
      "81 : conv_pw_11_relu, <keras.layers.core.Activation object at 0xd2ca8b860>\n",
      "82 : conv_pad_12, <keras.layers.convolutional.ZeroPadding2D object at 0xd2cb215f8>\n",
      "83 : conv_dw_12, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2cb21fd0>\n",
      "84 : conv_dw_12_bn, <keras.layers.normalization.BatchNormalization object at 0xd2cb50940>\n",
      "85 : conv_dw_12_relu, <keras.layers.core.Activation object at 0xd2cb9d860>\n",
      "86 : conv_pw_12, <keras.layers.convolutional.Conv2D object at 0xd2cc30e48>\n",
      "87 : conv_pw_12_bn, <keras.layers.normalization.BatchNormalization object at 0xd2cc30780>\n",
      "88 : conv_pw_12_relu, <keras.layers.core.Activation object at 0xd2ccaab38>\n",
      "89 : conv_pad_13, <keras.layers.convolutional.ZeroPadding2D object at 0xd2cd8ef28>\n",
      "90 : conv_dw_13, <keras.layers.convolutional.DepthwiseConv2D object at 0xd2cd40e10>\n",
      "91 : conv_dw_13_bn, <keras.layers.normalization.BatchNormalization object at 0xd2cd40da0>\n",
      "92 : conv_dw_13_relu, <keras.layers.core.Activation object at 0xd2ce46d68>\n",
      "93 : conv_pw_13, <keras.layers.convolutional.Conv2D object at 0xd2ce87710>\n",
      "94 : conv_pw_13_bn, <keras.layers.normalization.BatchNormalization object at 0xd2cec3f60>\n",
      "95 : conv_pw_13_relu, <keras.layers.core.Activation object at 0xd2cef29b0>\n",
      "96 : global_average_pooling2d_1, <keras.layers.pooling.GlobalAveragePooling2D object at 0xd2cf83668>\n",
      "97 : reshape_1, <keras.layers.core.Reshape object at 0xd2d0003c8>\n",
      "98 : conv_preds, <keras.layers.convolutional.Conv2D object at 0xd2cf83e48>\n",
      "99 : act_softmax, <keras.layers.core.Activation object at 0xd2cfb49b0>\n",
      "100 : reshape_2, <keras.layers.core.Reshape object at 0xd2d0939b0>\n"
     ]
    }
   ],
   "source": [
    "# Convert the loaded Keras model into a CoreML Model\n",
    "# Provide image_input_names to specify it is an image model\n",
    "# also provide the bias values specified by the model\n",
    "mlmodel = coremltools.converters.keras.convert(model, \n",
    "                                               input_names=['image'], \n",
    "                                               image_input_names=['image'],\n",
    "                                               output_names=['classLabelProbs', 'classLabel'],\n",
    "                                               class_labels='labels.txt', \n",
    "                                               blue_bias=-1,\n",
    "                                               green_bias=-1,\n",
    "                                               red_bias=-1, \n",
    "                                               image_scale=2./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model as a .mlmodel file which can be deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('ModelZoo/MobileNet.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now extract the model using the TensorFlow session to convert it for Android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ModelZoo/MobileNet.pb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = K.get_session()\n",
    "constant_graph = graph_util.convert_variables_to_constants(S, \n",
    "                                                           S.graph.as_graph_def(),\n",
    "                                                           ['reshape_2/Reshape'])\n",
    "graph_io.write_graph(constant_graph, 'ModelZoo/', 'MobileNet.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To convert the model for TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "model = MobileNet(weights='imagenet',\n",
    "                    input_tensor=input_tensor,\n",
    "                    include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: MobileNet.h5/temp-b'1551761065'/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: MobileNet.h5/temp-b'1551761065'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "keras_file = \"MobileNet.h5\"\n",
    "L = tf.contrib.saved_model.save_keras_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MobileNet.h5/1551761065/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MobileNet.h5/1551761065/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: input_1:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: input_1:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: reshape_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: reshape_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: reshape_2/Reshape:0, shape: (-1, 1000), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: reshape_2/Reshape:0, shape: (-1, 1000), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MobileNet.h5/1551761065/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MobileNet.h5/1551761065/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16897156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.contrib.lite.TFLiteConverter.from_saved_model(L)\n",
    "tflite_model = converter.convert()\n",
    "open('ModelZoo/'+\"MobileNet.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the model and get the details of the converted model\n",
    "### These are useful when deploying the models on Android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'input_1', 'index': 103, 'shape': array([  1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}] [{'name': 'reshape_2/Reshape', 'index': 106, 'shape': array([   1, 1000], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.contrib.lite.Interpreter(model_path='ModelZoo/MobileNet.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details, output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
